{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sPZTHfp1hIh",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "!pip3 install torch torchvision torchaudio transformers sentencepiece accelerate --extra-index-url https://download.pytorch.org/whl/cu116"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPQI4tT41rbn",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Import dependencies\n",
        "# Load ProtT5 in half-precision (more specifically: the encoder-part of ProtT5-XL-U50) \n",
        "from transformers import T5Tokenizer, T5EncoderModel\n",
        "import torch\n",
        "import re\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device: {}\".format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gd2WVxKk4nSb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Load encoder-part of ProtT5 in half-precision\n",
        "# Load ProtT5 in half-precision (more specifically: the encoder-part of ProtT5-XL-U50 in half-precision) \n",
        "transformer_link = \"Rostlab/prot_t5_xl_half_uniref50-enc\"\n",
        "print(\"Loading: {}\".format(transformer_link))\n",
        "model = T5EncoderModel.from_pretrained(transformer_link)\n",
        "model.full() if device=='cpu' else model.half() # only cast to full-precision if no GPU is available\n",
        "model = model.to(device)\n",
        "model = model.eval()\n",
        "tokenizer = T5Tokenizer.from_pretrained(transformer_link, do_lower_case=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "x_63qC0qkWgw"
      },
      "outputs": [],
      "source": [
        "#@title Set paths\n",
        "SEQUENCE_PATH = '/sample_data/362663.protein.sequences.v11.5.fa'\n",
        "LINKS_PATH = '/sample_data/362663.protein.links.v11.5.txt'\n",
        "EMBEDDING_PATH = '/sample_data/embedding.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZsoW33nCy3R",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Load sequence data and protein names\n",
        "f = open(SEQUENCE_PATH)\n",
        "sequence_examples = ''.join(f.readlines()).split('>')\n",
        "sequence_names = []\n",
        "for i in range(1,len(sequence_examples)):\n",
        "  sequence_examples[i] = sequence_examples[i].split(\"\\n\")\n",
        "  sequence_names.append(sequence_examples[i].pop(0))\n",
        "  sequence_examples[i] = ''.join(sequence_examples[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFfgawZH4AfP",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Generate input ids and attention mask\n",
        "# this will replace all rare/ambiguous amino acids by X and introduce white-space between all amino acids\n",
        "sequence_examples = [\" \".join(list(re.sub(r\"[UZOB]\", \"X\", sequence))) for sequence in sequence_examples]\n",
        "\n",
        "# tokenize sequences and pad up to the longest sequence in the batch\n",
        "ids = tokenizer.batch_encode_plus(sequence_examples, add_special_tokens=True, padding=\"longest\")\n",
        "input_ids = torch.tensor(ids['input_ids']).to(device)\n",
        "attention_mask = torch.tensor(ids['attention_mask']).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "hAg6fIKcZD90",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Run ProtBERT on input_ids and generate hidden layer\n",
        "N = len(input_ids)\n",
        "Z = torch.zeros(N, 1024)\n",
        "for i in range(N):\n",
        "  try:\n",
        "    with torch.no_grad():\n",
        "      Z[i] = model(input_ids=input_ids[i:(i+1)],attention_mask=attention_mask[i:(i+1)]).last_hidden_state[:,:7].mean(dim=1)\n",
        "    c += 1\n",
        "    if c > N/500:\n",
        "      print(i/N*100)\n",
        "      c = 0\n",
        "  except:\n",
        "    print(\"Crashed at i = \", i)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2Tkn_gIe28P",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Save node embeddings\n",
        "torch.save(Z ,EMBEDDING_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3DFqfQkpkQD1"
      },
      "outputs": [],
      "source": [
        "#@title Load node embeddings\n",
        "Z = torch.load(EMBEDDING_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stUfKNMomAL8",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Load protein links\n",
        "f = open(LINKS_PATH)\n",
        "f.readline()\n",
        "edges = [line.split(' ')[0:2] for line in f.readlines()]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}